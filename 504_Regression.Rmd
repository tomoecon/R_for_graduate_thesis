```{r library Regression, echo = FALSE}
library(tidyverse)
library(broom)
library(wooldridge)
library(stargazer)
data("saving")
```

# 回帰分析 {#Regression}

【Section \@ref(movieRegression)に関連動画を紹介しています。】

回帰分析とは、従属変数と独立変数の関係を数式（モデル）で表し、そのパラメータを推定する分析方法です。
ここでは、もっとも基本的な回帰分析である線形回帰（Linear Regression）を扱います。

## 線形回帰とは

線形回帰では、従属変数 $y$ と説明変数 $x$ があるとき、$y$ と $x$ の関係の以下の式（回帰式）で表します。

<br>
<center>
$y = \alpha + \beta x$
</center>
<br>

別の言い方をすると、 $y$ を $x$ の１次関数で表すと言うことです。
傾きを示す $\beta$ は $x$ と $y$ の関係を示す重要な数値で、係数（Coefficient）と呼ばれます。
これがプラスであれば $x$ と $y$ に正の関係があることになりますし、マイナスであれば負の関係、0であれば関係がないことになります。
$\beta$ は $x$ が1単位高いとき、$y$ が $\beta$ 単位高い、という意味になります。
**回帰分析では変数の単位を常に把握して分析するよう心がけましょう。**

$\alpha$ や $\beta$ は最小二乗法（OLS）という方法で推定します。
この文書ではRでの操作方法に特化して説明するので、詳しくは各自調べてください。

## Rでの線形回帰

Rでは回帰式を`y ~ x`と表記します。（ここはChapter \@ref(Ttest)で学んだとt検定同じ表記です）
線形回帰を行う関数が`lm()`で（lmはlinear modelの略）、以下のように表記します。

```{r regression, eval = FALSE}
lm(回帰式, data = データフレーム)
```

例として、従属変数を年収`inc`、独立変数を教育年数`educ`とした線形回帰分析を行ってみましょう。
回帰式は $inc = \alpha + \beta educ$ です。

```{r regression inc ~ educ}
lm(inc ~ educ, data = saving)
```

Coefficientsのinterceptが$\alpha$、educが$\beta$を表します。
$\beta$を見ると、教育年数が1年高いと年収が742.5ドル高くなっていることがわかります。

`lm()`を実施すると、以上のように係数の推定値を得ることができますが、統計的推測のための数値（t値、p値）がわかりません。
`lm()`の結果を`summary()`に渡すと、詳細を見ることができます。

```{r regression summary}
lm(inc ~ educ, data = saving) %>%
  summary()
```

Coefficientsで以下の数値が表示されるようになりました。
それぞれの意味は教科書を確認してください。

- `Estimate`: 係数
- `Std. Error`: 標準誤差
- `t value`: t値
- `Pr(>|t|)`: p値

`educ`のp値は1.78e-06と表記されています。
これは、$1.78 \times 10^{-6} = 1.78 \times 0.000001 = 0.00000178$を表します。
とても小さい値なので、`educ`の係数 $\beta$ は有意に負と言えます。

他にも、決定係数 $R^2$ などの数値も記載されています。

`summary()`で詳細を見ることができますが、やや見づらい印象があります。
表形式にするため、Chapter \@ref(Ttest)と同じく`broom`パッケージの関数`tidy()`を使ってみましょう。

```{r regression tidy}
lm(inc ~ educ, data = saving) %>%
  tidy()
```

表形式で見やすくなりました。

★練習問題

- 収入`inc`を世帯人数`size`に回帰し、係数の意味を解釈してください。

## 重回帰分析

回帰分析には複数の説明変数を含め、それぞれの説明変数と被説明変数との変数を検証することができます。
複数の説明変数がある回帰分析を重回帰分析、一方上で説明した１つの説明変数がある回帰分析を単回帰分析と呼びます。
回帰式は説明変数を $x_1, x_2$ としたとき、以下のようになります。

<br>
<center>
$y = \alpha + \beta_1 x_1 + \beta_2 x_2$
</center>
<br>

Rでの回帰式の表記は、`y ~ x1 + x2`と、説明変数を`+`でつなげます。
ここでは、収入`inc`を教育年数`educ`と世帯人数`size`に回帰してみましょう。

```{r multiple regression}
lm(inc ~ educ + size, data = saving) %>%
  tidy()
```
回帰式の解釈は単回帰分析と同様です。
ここでは、教育年数の結果は先ほどと大きく変わりませんでした。

説明変数はさらに3つ、4つ…と増やすことができ、Rでは`y ~ x1 + x2 + x3 + x4 + ...`と`+`でつなげていきます。
説明変数が多く回帰式が長くなる場合は、回帰式を一旦オブジェクトとして保存しておくとコードが読みやすくなります。

例えば、上記の回帰分析にさらに年齢`age`、黒人ダミー`black`を加えてみましょう。

```{r multiple regression using object}
equation <- inc ~ educ + size + age + black
lm(equation, data = saving) %>%
  tidy()
```

4つの説明変数による回帰分析の結果が出力できました。黒人ダミーの解釈については、次項をご覧ください。

★練習問題

- 貯蓄額`sav`を被説明変数、教育年数`educ`、世帯人数`size`、年齢`age`を説明変数とする回帰分析を行い、それぞれの係数を解釈しなさい。

## ダミー変数の利用

条件を満たすグループに1、条件を満たさないグループに0をとるダミー変数は、そのまま回帰分析に組み込むことができます。
ただし、解釈には注意が必要です。
ダミー変数の係数の解釈は、「条件を満たすグループは満たさないグループと比べて、被説明変数が（係数）大きい」となります。

ここでは、収入`inc`を黒人ダミー`black`に回帰してみましょう。

```{r regression dummy}
lm(inc ~ black, data = saving)
```

黒人ダミーの係数は-3418です。これは、「黒人はそれ以外と比べて、年収が3418ドル低い」ことを意味します。

## カテゴリ変数の利用

カテゴリ変数はそのまま回帰分析に組み込むことができません。
代わりにカテゴリの数-1個のダミー変数を作成し、回帰分析に組み込みます。
例えば、A, B, Cという3つのカテゴリがある場合、

- Bであれば1、そうでなければ0をとる「Bダミー」
- Cであれば1、そうでなければ0をとる「Cダミー」

を作成し、回帰分析の独立変数として両方入れます。
係数の解釈には注意が必要です。それぞれの係数の解釈は、ダミー変数として入っていない「参照レベル」との比較となります。

- Bダミーの係数は「カテゴリBはカテゴリAと比べて被説明変数が（係数）大きい」
- Cダミーの係数は「カテゴリCはカテゴリAと比べて被説明変数が（係数）大きい」

カテゴリBとカテゴリCを比べたい場合は、双方の係数を比較してください。

Rではカテゴリ変数がfactor型になっていれば、**自動的にダミー変数を作成して**回帰分析に入れてくれます。（もちろん、自分で作成しても構いませんし、そのほうが良い場合もあります）

ここでは、年齢のカテゴリ変数`age_category`を作成し、年収`inc`に対する回帰分析に組み込んでみましょう。

```{r regression category}
saving_with_age_category <-
  saving %>%
    mutate(age_category = case_when(age < 30 ~ "20s",
                                    age >= 30 & age < 40 ~ "30s",
                                    age >= 40 & age < 50 ~ "40s",
                                    age >= 50 ~ "50s"
                                    )
          )

lm(inc ~ age_category, data = saving_with_age_category)
```

ここでは自動的に"20s"が参照レベルとなり、回帰分析には含まれていません。
各係数は20代と比べて収入がどれくらい高いかを表します。

- 30代は20代より年収が1330ドル高い
- 40代は20代より年収が3761ドル高い
- 50代は20代より年収が3885ドル高い

それぞれ比較すると、年収は20代<30代<40代<50代と年齢が上がるにつれ高くなることがわかります。
しかし、40代と50代では差はほぼありません。

## 交互作用の導入

ある説明変数と被説明変数のとの関係が別の説明変数によって変化するような状況のことを交互作用がある、と言います。
例えば、収入と教育年数の関係が黒人ダミーによって異なる、といった場合です。
Rの回帰式では、交互作用は2つの変数を`:`でつなげることで表現できます。
上記の例をRで実施してみましょう。

```{r interaction}
lm(inc ~ educ + black + educ:black, data = saving) %>%
  tidy()
```

交互作用の解釈は少し複雑になります。
まずここでは教育年数`educ`の係数が727なので、教育年数1年高いと収入が727ドル高いことになります。
これは参照レベルである「黒人以外」での教育年数と収入の関係になります。

交互作用`educ:black`は-63ですが、これは黒人での教育年数と収入の係数が727-63=664であることを意味します。
なので、黒人では教育年数が1年高いと収入が664ドル高いということになります。
ただし、ここでは交互作用のp値が大きく有意ではありません。
すなわち、「黒人とそれ以外では教育年数と収入の関係が同じ」という仮説は棄却できていません。

交互作用の分析の際は、交互作用に使用した変数単体も必ず回帰式に含めるようにしてください。
`*`を使用すると、単体・相互作用をすべて自動的に作成・分析してくれます。

```{r interaction using asterisk}
lm(inc ~ educ*black, data = saving) %>%
  tidy()
```

前の分析と全く同じ結果となっています。

★練習問題

- 収入`inc`と年齢`age`の関係が黒人ダミーによって異なるかどうか、交互作用を含めた回帰分析を行い、その結果を解釈しなさい。


## 回帰分析の表をまとめる

ここまでは、回帰分析の結果は`tidy()`を用いて整理し、卒業論文に貼り付ける想定で話を進めてきました。
回帰分析の数が少ない場合は、この方法でも十分でしょう。

しかし、実施した回帰分析が多い場合、同じような表が続き冗長になります。
ここでは、`stargazer`パッケージを用いて、複数の回帰分析の結果をまとめた表を作成してみる方法を説明します。

以下の2つの回帰分析をまとめて表にしてみましょう。

1. 被説明変数を収入`inc`、説明変数を教育年数`educ`とする単回帰分析
2. 被説明変数を収入`inc`、説明変数を教育年数`educ`と年齢`age`とする重回帰分析

`stargazer()`では、回帰分析結果を保存したオブジェクト

```{r stargazer, results = "asis"}
regression1 <- lm(inc ~ educ, data = saving) #単回帰分析の結果をオブジェクトに保存
regression2 <- lm(inc ~ educ + age, data = saving) #重回帰分析の結果をオブジェクトに保存
stargazer(regression1, regression2, type = "html", out = "test.doc")
```

1・2行目では、`lm()`で回帰分析を行い、結果をオブジェクトとして`regression1`,`regression2`にそれぞれ入力しています。
`stargazer()`では、表に含める回帰分析の結果を引数とし、さらにオプションを指定します。
`type`はデフォルトではLaTeXになっており多くの方は使えないと思いますので、ここではHTMLを指定して表形式に整えます。
`out`を指定すると、結果をファイルとして保存できます。
このファイルの表を卒業論文に貼り付け、必要に応じて加工すると良いでしょう。

表は列ごとに回帰分析の結果を示しています。
各行は説明変数を表し、かっこの無い上側が係数、かっこのある下側が標準誤差を表しています。
また、アスタリスク\*で有意水準を表しています。
\*\*\*が有意水準1%で有意、\*\*が有意水準5%で有意、\*が有意水準10%で有意であることを示します。

線の下は以下のものを表しています。重要な情報なので、そのまま残しておきましょう。

- `Observation`: 観測数
- $R^2$: 決定係数
- `Adjusted` $R^2$: 修正済み決定係数
- `Residual Std. Error`: 残差の標準誤差
- `F Statistic`: F値（F検定の結果も合わせて表示）

## 関連動画 {#movieRegression}

```{r yt reg, eval=knitr::is_html_output(excludes = "epub"), results = 'asis', echo = F, fig.align = 'center'}
cat(
'<iframe width="560" height="315" 
  src="https://www.youtube.com/embed/6VeJdNhah5A"
  frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
  </iframe>'
)
```

```{r yt regdum, eval=knitr::is_html_output(excludes = "epub"), results = 'asis', echo = F, fig.align = 'center'}
cat(
'<iframe width="560" height="315" 
  src="https://www.youtube.com/embed/dCPxYHAvMU8"
  frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
  </iframe>'
)
```

```{r yt regint, eval=knitr::is_html_output(excludes = "epub"), results = 'asis', echo = F, fig.align = 'center'}
cat(
'<iframe width="560" height="315" 
  src="https://www.youtube.com/embed/9phaZKUPXAI"
  frameborder="0" allow="accelerometer; autoplay; encrypted-media;
  gyroscope; picture-in-picture" allowfullscreen>
  </iframe>'
)
```
